{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tranformers\n",
    "\n",
    "Beatriz Cabral Fernandes\n",
    "\n",
    "Leonardo Duarte Malta de Abreu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O transformer é uma arquitetura de rede neural que ganhou destaque com a introdução do modelo por Vaswani et al. em 2017 [1]. Essa abordagem superou muitas limitações encontradas em técnicas anteriores, e se tornou uma estratégia referência em Machine Learning. Sua eficácia tem sido amplamente comprovada em tarefas como tradução automática, análise de sentimento, resumo de texto e muito mais [2][3].\n",
    "\n",
    "A chave para o sucesso do transformer é proveniente da sua capacidade de capturar dependências de longo alcance e modelar interações complexas em sequências. Isso é alcançado por meio de um mecanismo chamado multi-head attention, que permite que o modelo pondere a importância de diferentes partes da sequência em cada etapa do processamento [1].\n",
    "\n",
    "Além de seu impacto na PNL (Programação Neurolinguística), o transformer também possuem aplicações promissoras em outros domínios, como o reconhecimento de imagens e o reconhecimento de áudio. A adaptação desse mecanismo para o processamento de imagens, transformando-as em sequências de patches, tem permitido avanços notáveis em tarefas de classificação e detecção de objetos [5].\n",
    "\n",
    "Neste trabalho, exploraremos em detalhes o conceito desse mecanismo, com ênfase em sua aplicação em PNL e reconhecimento de imagens, discutindo aplicações reais e exemplos concretos dessas arquiteturas em cada domínio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente\n",
    "\n",
    "### Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tensorflow.keras.datasets import imdb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo Download dos Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['KAGGLE_USERNAME'] = os.getenv('KAGGLE_USERNAME')\n",
    "os.environ['KAGGLE_KEY'] = os.getenv('KAGGLE_KEY')\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Define the Kaggle datasets to download\n",
    "dataset_names = ['lakshmi25npathi/imdb-dataset-of-50k-movie-reviews', 'muhammadhananasghar/human-emotions-datasethes']\n",
    "\n",
    "import kaggle\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "for dataset_name in dataset_names:\n",
    "    kaggle.api.dataset_download_files(dataset_name, path=data_dir, unzip=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como Funciona o Transformador?\n",
    "\n",
    "O Transformador inclui dois componentes principais: codificador (Encoder) e decodificador (Decoder).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png\" alt=\"Tranformer\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "O codificador é responsável por receber a entrada e processá-la, gerando uma representação intermediária que será utilizada pelo decodificador. Ele é composto por uma pilha de N camadas, cada uma contendo dois subcamadas: uma camada de atenção multi-head e uma camada totalmente conectada. Além disso, cada subcamada é seguida por uma camada de normalização residual [1]. Já o decodificador é responsável por gerar a saída, recebendo como entrada a representação intermediária gerada pelo codificador. Ele também é composto por uma pilha de N camadas, cada uma contendo três subcamadas: uma camada de atenção multi-head, uma camada de atenção multi-head que recebe a saída da camada anterior como entrada e uma camada totalmente conectada. Assim como no codificador, cada subcamada é seguida por uma camada de normalização residual [1].\n",
    "\n",
    "O tranformador possui inúmeras etapas, e para explicar cada uma delas, utiliza-se um Dataset de Reviews de Filmes, onde cada review é uma sequência de palavras. O objetivo é classificar se a review é positiva ou negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Embedding\n",
    "\n",
    "O primeiro passo é converter cada palavra em um vetor de números reais. Para isso, utiliza-se uma camada de embedding, que é treinada juntamente com o modelo. Essa camada é responsável por mapear cada palavra para um vetor de tamanho d, onde d é a dimensão do embedding. Essa camada é compartilhada entre o codificador e o decodificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 0s 0us/step\n",
      "133/281 [=============>................] - ETA: 34s"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "vocab_size = 10000  # tamanho do vocabulário\n",
    "max_sequence_length = 500  # comprimento máximo da sequência\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=vocab_size)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_sequence_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_sequence_length)\n",
    "\n",
    "embedding_dim = 256  # dimensão dos embeddings\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "\n",
    "embedded_input = model.predict(x_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1] Vaswani, A., et al. (2017). \"Attention Is All You Need.\"\n",
    "\n",
    "[2] Devlin, J., et al. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\"\n",
    "\n",
    "[3] Brown, T. B., et al. (2020). \"Language Models are Few-Shot Learners.\"\n",
    "\n",
    "[5] Dosovitskiy, A., et al. (2020). \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.\"\n",
    "\n",
    "[6] Huang, Y., et al. (2021). \"T2T-ViT: Token-to-Token Vision Transformers for Efficient Image Processing.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
